<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>44febb0e62e04e2ca739c88eb7e8148e</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section
id="goal-convolutionl-network-with-width-normalization-in-preprocessing-on-mnist-database"
class="cell markdown" id="bqQ43GDXLVLz">
<h1>Goal: convolutionl network with width normalization in preprocessing
on MNIST database</h1>
<p>convolutional networks perform feature extraction</p>
<p>general steps of convolutional networks:</p>
<ol>
<li>filter with a convolution layer</li>
<li>detect with ReLU activation</li>
<li>condense with a maximum pooling layer</li>
</ol>
<p>The sliding window:</p>
<p>a. The convolution and pooling operations share a common feature:
they are both performed over a sliding window. With convolution, this
"window" is given by the dimensions of the kernel, the parameter
kernel_size. With pooling, it is the pooling window, given by
pool_size.</p>
<p>b. There are two additional parameters affecting both convolution and
pooling layers -- these are the strides of the window and whether to use
padding at the image edges. The strides parameter says how far the
window should move at each step, and the padding parameter describes how
we handle the pixels at the edges of the input.</p>
<p>c. Because we want high-quality features to use for classification,
convolutional layers will most often have strides=(1, 1). Increasing the
stride means that we miss out on potentially valuble information in our
summary. Maximum pooling layers, however, will almost always have stride
values greater than 1, like (2, 2) or (3, 3), but not larger than the
window itself.</p>
<h2 id="procedure">Procedure</h2>
<p>Step 1: Load the data</p>
<p>Step 2: Define Model</p>
<p>Step 3: Train</p>
<p>-&gt; Boost performance by creating extra training data</p>
</section>
<div class="cell code" id="zMtyZlexKJoA">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#path = &quot;/kaggle/input/digit-recognizer/train.csv&quot;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#mnist = pd.read_csv(path)</span></span></code></pre></div>
</div>
<div class="cell code" id="ynsStCttA2JE">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.datasets <span class="im">import</span> cifar10, mnist</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> Sequential</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>tf.random.set_seed(<span class="dv">0</span>)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="D53Q0NUoA5V7" data-outputId="2742c522-edae-4ef2-af2c-9636081f91db">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> mnist.load_data()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434 [==============================] - 0s 0us/step
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="0uSQC-uaA-PS" data-outputId="8907ff93-2507-4573-da38-fe5051357189">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>s1 <span class="op">=</span> x_train.shape</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>s2 <span class="op">=</span> x_test.shape</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;The MNIST data was loaded with </span><span class="sc">{</span>s1[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> training samples and </span><span class="sc">{</span>s2[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> testing samples.&quot;</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Each sample is a </span><span class="sc">{</span>s1[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> x </span><span class="sc">{</span>s1[<span class="dv">2</span>]<span class="sc">}</span><span class="ss"> pixel image.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The MNIST data was loaded with 60000 training samples and 10000 testing samples.
Each sample is a 28 x 28 pixel image.
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="01jdnSacFsFq" data-outputId="0632a6c3-fb2f-4052-bf11-def97f26c49b">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define width normalization function using Lambda layer</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> width_normalization(x):</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> tf.math.reduce_mean(x, axis<span class="op">=-</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> tf.math.reduce_std(x, axis<span class="op">=-</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x <span class="op">-</span> mean) <span class="op">/</span> std</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Load MNIST dataset</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> keras.datasets.mnist.load_data()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize pixel values to range [0, 1]</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> x_train.astype(<span class="st">&quot;float32&quot;</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> x_test.astype(<span class="st">&quot;float32&quot;</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Add channel dimension to images</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> np.expand_dims(x_train, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> np.expand_dims(x_test, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Define models</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model(use_width_norm<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(inputs)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> layers.Flatten()(x)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_width_norm:</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(x)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.BatchNormalization()(x)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.Lambda(width_normalization)(x)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(x)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(x)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(x)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> keras.Model(inputs, outputs)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Create models and compile them</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>model_no_norm <span class="op">=</span> get_model(use_width_norm<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>model_norm <span class="op">=</span> get_model(use_width_norm<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> keras.optimizers.legacy.Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>model_no_norm.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;sparse_categorical_crossentropy&quot;</span>, optimizer<span class="op">=</span>opt, metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>model_norm.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;sparse_categorical_crossentropy&quot;</span>, optimizer<span class="op">=</span>opt, metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Train models</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>history_no_norm <span class="op">=</span> model_no_norm.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">20</span>, validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>history_norm <span class="op">=</span> model_norm.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">20</span>, validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate models on test set</span></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>test_loss_no_norm, test_acc_no_norm <span class="op">=</span> model_no_norm.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>test_loss_norm, test_acc_norm <span class="op">=</span> model_norm.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Model without width normalization&quot;</span>)</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test accuracy: </span><span class="sc">{</span>test_acc_no_norm<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, np.argmax(model_no_norm.predict(x_test), axis<span class="op">=</span><span class="dv">1</span>)))</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>cm_no_norm <span class="op">=</span> confusion_matrix(y_test, np.argmax(model_no_norm.predict(x_test), axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm_no_norm, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">&quot;Blues&quot;</span>)</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Confusion matrix - model without width normalization&quot;</span>)</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Model with width normalization&quot;</span>)</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Test accuracy: </span><span class="sc">{</span>test_acc_norm<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, np.argmax(model_norm.predict(x_test), axis<span class="op">=</span><span class="dv">1</span>)))</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>cm_norm <span class="op">=</span> confusion_matrix(y_test, np.argmax(model_norm.predict(x_test), axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm_norm, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">&quot;Blues&quot;</span>)</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Confusion matrix - model with width normalization&quot;</span>)</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot accuracy and loss curves</span></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>plt.plot(history_no_norm.history[<span class="st">&quot;accuracy&quot;</span>], label<span class="op">=</span><span class="st">&quot;Training accuracy - no norm&quot;</span>)</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/20
1500/1500 [==============================] - 41s 27ms/step - loss: 0.1750 - accuracy: 0.9462 - val_loss: 0.0911 - val_accuracy: 0.9728
Epoch 2/20
1500/1500 [==============================] - 40s 27ms/step - loss: 0.0589 - accuracy: 0.9821 - val_loss: 0.0682 - val_accuracy: 0.9808
Epoch 3/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.0564 - val_accuracy: 0.9832
Epoch 4/20
1500/1500 [==============================] - 37s 25ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0562 - val_accuracy: 0.9835
Epoch 5/20
1500/1500 [==============================] - 38s 26ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0558 - val_accuracy: 0.9846
Epoch 6/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0525 - val_accuracy: 0.9859
Epoch 7/20
1500/1500 [==============================] - 38s 26ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0653 - val_accuracy: 0.9848
Epoch 8/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0612 - val_accuracy: 0.9854
Epoch 9/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0862 - val_accuracy: 0.9832
Epoch 10/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0717 - val_accuracy: 0.9862
Epoch 11/20
1500/1500 [==============================] - 37s 25ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0911 - val_accuracy: 0.9837
Epoch 12/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0819 - val_accuracy: 0.9850
Epoch 13/20
1500/1500 [==============================] - 41s 28ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0747 - val_accuracy: 0.9873
Epoch 14/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0763 - val_accuracy: 0.9865
Epoch 15/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9846
Epoch 16/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0848 - val_accuracy: 0.9847
Epoch 17/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0913 - val_accuracy: 0.9852
Epoch 18/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0897 - val_accuracy: 0.9852
Epoch 19/20
1500/1500 [==============================] - 37s 25ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0823 - val_accuracy: 0.9858
Epoch 20/20
1500/1500 [==============================] - 39s 26ms/step - loss: 7.3484e-04 - accuracy: 0.9998 - val_loss: 0.0953 - val_accuracy: 0.9848
Epoch 1/20
1500/1500 [==============================] - 40s 26ms/step - loss: 0.1261 - accuracy: 0.9613 - val_loss: 0.0708 - val_accuracy: 0.9774
Epoch 2/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0504 - accuracy: 0.9837 - val_loss: 0.0615 - val_accuracy: 0.9822
Epoch 3/20
1500/1500 [==============================] - 40s 27ms/step - loss: 0.0342 - accuracy: 0.9894 - val_loss: 0.0542 - val_accuracy: 0.9833
Epoch 4/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.0683 - val_accuracy: 0.9808
Epoch 5/20
1500/1500 [==============================] - 41s 27ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0541 - val_accuracy: 0.9853
Epoch 6/20
1500/1500 [==============================] - 41s 27ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0543 - val_accuracy: 0.9847
Epoch 7/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0636 - val_accuracy: 0.9830
Epoch 8/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0539 - val_accuracy: 0.9861
Epoch 9/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0585 - val_accuracy: 0.9858
Epoch 10/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0616 - val_accuracy: 0.9857
Epoch 11/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0633 - val_accuracy: 0.9859
Epoch 12/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0631 - val_accuracy: 0.9847
Epoch 13/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0614 - val_accuracy: 0.9865
Epoch 14/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0538 - val_accuracy: 0.9868
Epoch 15/20
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0598 - val_accuracy: 0.9864
Epoch 16/20
1500/1500 [==============================] - 41s 27ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0632 - val_accuracy: 0.9867
Epoch 17/20
1500/1500 [==============================] - 42s 28ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0602 - val_accuracy: 0.9874
Epoch 18/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0751 - val_accuracy: 0.9837
Epoch 19/20
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0619 - val_accuracy: 0.9865
Epoch 20/20
1500/1500 [==============================] - 38s 26ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0616 - val_accuracy: 0.9868
Model without width normalization
Test accuracy: 0.9857000112533569
313/313 [==============================] - 3s 8ms/step
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       1.00      0.99      0.99      1135
           2       0.99      0.99      0.99      1032
           3       0.99      0.98      0.98      1010
           4       0.99      0.98      0.99       982
           5       0.98      0.98      0.98       892
           6       0.99      0.98      0.99       958
           7       0.98      0.99      0.98      1028
           8       0.98      0.99      0.98       974
           9       0.98      0.98      0.98      1009

    accuracy                           0.99     10000
   macro avg       0.99      0.99      0.99     10000
weighted avg       0.99      0.99      0.99     10000

313/313 [==============================] - 3s 9ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_d4cb1db733bc4f36b0da75d6189c31f8/8b9808dc7843bd0d7700f4304127c2e417a8590f.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Model with width normalization
Test accuracy: 0.9861000180244446
313/313 [==============================] - 3s 8ms/step
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.99      0.98      1032
           3       0.99      0.99      0.99      1010
           4       0.99      0.99      0.99       982
           5       0.98      0.98      0.98       892
           6       0.99      0.98      0.99       958
           7       0.99      0.97      0.98      1028
           8       0.98      0.99      0.99       974
           9       0.98      0.98      0.98      1009

    accuracy                           0.99     10000
   macro avg       0.99      0.99      0.99     10000
weighted avg       0.99      0.99      0.99     10000

313/313 [==============================] - 3s 8ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_d4cb1db733bc4f36b0da75d6189c31f8/bb2fc75cf1a338ec9af11d896cb90ed189c6fa40.png" /></p>
</div>
<div class="output execute_result" data-execution_count="15">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7f9de66296f0&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_d4cb1db733bc4f36b0da75d6189c31f8/d1c1b671df140f8d4bb2fd6618ff724d10a43745.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:717}"
id="2A0DlrXE0v9z" data-outputId="6d18463f-8818-4bc8-d1fc-c7981dbb5a95">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ipywidgets <span class="im">as</span> widgets</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define width normalization function using Lambda layer</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> width_normalization(x):</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">=</span> tf.math.reduce_mean(x, axis<span class="op">=-</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> tf.math.reduce_std(x, axis<span class="op">=-</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x <span class="op">-</span> mean) <span class="op">/</span> std</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Load MNIST dataset</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> keras.datasets.mnist.load_data()</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize pixel values to range [0, 1]</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> x_train.astype(<span class="st">&quot;float32&quot;</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> x_test.astype(<span class="st">&quot;float32&quot;</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Add channel dimension to images</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> np.expand_dims(x_train, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> np.expand_dims(x_test, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Define models</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model(use_width_norm<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(inputs)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> layers.Flatten()(x)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_width_norm:</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(x)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.BatchNormalization()(x)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.Lambda(width_normalization)(x)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(x)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>)(x)</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)(x)</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> keras.Model(inputs, outputs)</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Create models and compile them</span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>model_no_norm <span class="op">=</span> get_model(use_width_norm<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>model_norm <span class="op">=</span> get_model(use_width_norm<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> keras.optimizers.legacy.Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>model_no_norm.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;sparse_categorical_crossentropy&quot;</span>, optimizer<span class="op">=</span>opt, metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>model_norm.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">&quot;sparse_categorical_crossentropy&quot;</span>, optimizer<span class="op">=</span>opt, metrics<span class="op">=</span>[<span class="st">&quot;accuracy&quot;</span>])</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Train models</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>history_no_norm <span class="op">=</span> model_no_norm.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>history_norm <span class="op">=</span> model_norm.fit(x_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate models on test set</span></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>test_loss_no_norm, test_acc_no_norm <span class="op">=</span> model_no_norm.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>test_loss_norm, test_acc_norm <span class="op">=</span> model_norm.evaluate(x_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert input image array to bytes</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>input_image_bytes <span class="op">=</span> x_test[<span class="dv">0</span>].tobytes()</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Define GUI elements</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>input_image <span class="op">=</span> widgets.Image(value<span class="op">=</span>input_image_bytes)</span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>no_norm_output <span class="op">=</span> widgets.Label(value<span class="op">=</span><span class="ss">f&quot;Prediction: None&quot;</span>)</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>norm_output <span class="op">=</span> widgets.Label(value<span class="op">=</span><span class="ss">f&quot;Prediction: None&quot;</span>)</span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>button_no_norm <span class="op">=</span> widgets.Button(description<span class="op">=</span><span class="st">&quot;No Norm Prediction&quot;</span>)</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>button_norm <span class="op">=</span> widgets.Button(description<span class="op">=</span><span class="st">&quot;Norm Prediction&quot;</span>)</span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Define prediction</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/10
1500/1500 [==============================] - 44s 28ms/step - loss: 0.1616 - accuracy: 0.9515 - val_loss: 0.0865 - val_accuracy: 0.9729
Epoch 2/10
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 0.0606 - val_accuracy: 0.9833
Epoch 3/10
1500/1500 [==============================] - 41s 27ms/step - loss: 0.0336 - accuracy: 0.9898 - val_loss: 0.0634 - val_accuracy: 0.9811
Epoch 4/10
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0532 - val_accuracy: 0.9851
Epoch 5/10
1500/1500 [==============================] - 38s 26ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0613 - val_accuracy: 0.9831
Epoch 6/10
1500/1500 [==============================] - 38s 26ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0569 - val_accuracy: 0.9847
Epoch 7/10
1500/1500 [==============================] - 40s 26ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0638 - val_accuracy: 0.9843
Epoch 8/10
1500/1500 [==============================] - 40s 26ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0729 - val_accuracy: 0.9837
Epoch 9/10
1500/1500 [==============================] - 38s 25ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0731 - val_accuracy: 0.9862
Epoch 10/10
1500/1500 [==============================] - 37s 25ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0712 - val_accuracy: 0.9871
Epoch 1/10
1500/1500 [==============================] - 41s 26ms/step - loss: 0.1254 - accuracy: 0.9623 - val_loss: 0.0702 - val_accuracy: 0.9787
Epoch 2/10
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0492 - accuracy: 0.9846 - val_loss: 0.0587 - val_accuracy: 0.9829
Epoch 3/10
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0331 - accuracy: 0.9899 - val_loss: 0.0629 - val_accuracy: 0.9818
Epoch 4/10
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0548 - val_accuracy: 0.9843
Epoch 5/10
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0580 - val_accuracy: 0.9836
Epoch 6/10
1500/1500 [==============================] - 41s 27ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0646 - val_accuracy: 0.9836
Epoch 7/10
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0698 - val_accuracy: 0.9824
Epoch 8/10
1500/1500 [==============================] - 41s 28ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0586 - val_accuracy: 0.9849
Epoch 9/10
1500/1500 [==============================] - 39s 26ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0617 - val_accuracy: 0.9851
Epoch 10/10
1500/1500 [==============================] - 41s 27ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0559 - val_accuracy: 0.9867
</code></pre>
</div>
</div>
<div class="cell code" id="nU_ExLT5K-si">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:215,&quot;referenced_widgets&quot;:[&quot;88754cff593f49abb8f9fa4fcbc6a404&quot;,&quot;5aa9faf660f64e74839cdefae2c8006b&quot;,&quot;33ee9d85a33245b18721536eb11a0eb7&quot;,&quot;211b9beb6b4d4afda02e92e32af0170b&quot;,&quot;d8caee2ce45c41f8ab5610e6076bf9f4&quot;,&quot;5a470a91501c470ab5c190d6b78107b4&quot;,&quot;80b91e5b6e3c43c18fab829e67b267e1&quot;,&quot;2fcce236d63d4eb2ac06c75ca3647195&quot;,&quot;58b3f463668e4ff6ac2622093e2ca928&quot;,&quot;b6136b9b64c84ca79d21bcc77fb71018&quot;,&quot;63cf4c914de24f05bce990738d1d2c96&quot;,&quot;b736483efc214ec28ca1a4748e42b1c0&quot;,&quot;b6749fa3bc44402ea9edfe39529d7d80&quot;,&quot;f91de7f7db694684adddef883400c624&quot;]}"
id="o9aKyKEFMO6y" data-outputId="90949db7-9b57-43ae-a796-2c777b39a431">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predictions for a sample input image</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>sample_image <span class="op">=</span> x_test[<span class="dv">0</span>:<span class="dv">1</span>]  <span class="co"># select the first image from the test set</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>no_norm_prediction <span class="op">=</span> np.argmax(model_no_norm.predict(sample_image), axis<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>norm_prediction <span class="op">=</span> np.argmax(model_norm.predict(sample_image), axis<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert input image array to bytes</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>input_image_pil <span class="op">=</span> Image.fromarray((<span class="dv">255</span> <span class="op">*</span> x_test[<span class="dv">0</span>].reshape(<span class="dv">28</span>, <span class="dv">28</span>)).astype(np.uint8))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>input_image_bytes <span class="op">=</span> io.BytesIO()</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>input_image_pil.save(input_image_bytes, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;png&#39;</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>input_image_bytes <span class="op">=</span> input_image_bytes.getvalue()</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Define GUI elements</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>input_image <span class="op">=</span> widgets.Image(value<span class="op">=</span>input_image_bytes)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>no_norm_output <span class="op">=</span> widgets.Label(value<span class="op">=</span><span class="ss">f&quot;Prediction: </span><span class="sc">{</span>no_norm_prediction<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>norm_output <span class="op">=</span> widgets.Label(value<span class="op">=</span><span class="ss">f&quot;Prediction: </span><span class="sc">{</span>norm_prediction<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>button_no_norm <span class="op">=</span> widgets.Button(description<span class="op">=</span><span class="st">&quot;No Norm Prediction&quot;</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>button_norm <span class="op">=</span> widgets.Button(description<span class="op">=</span><span class="st">&quot;Norm Prediction&quot;</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Define prediction functions for the buttons</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_no_norm(button):</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> np.argmax(model_no_norm.predict(sample_image), axis<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    no_norm_output.value <span class="op">=</span> <span class="ss">f&quot;Prediction: </span><span class="sc">{</span>prediction<span class="sc">}</span><span class="ss">&quot;</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_norm(button):</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    prediction <span class="op">=</span> np.argmax(model_norm.predict(sample_image), axis<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    norm_output.value <span class="op">=</span> <span class="ss">f&quot;Prediction: </span><span class="sc">{</span>prediction<span class="sc">}</span><span class="ss">&quot;</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Attach the prediction functions to the buttons</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>button_no_norm.on_click(predict_no_norm)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>button_norm.on_click(predict_norm)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the GUI elements</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>display(input_image)</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>display(button_no_norm)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>display(no_norm_output)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>display(button_norm)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>display(norm_output)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>1/1 [==============================] - 0s 45ms/step
1/1 [==============================] - 0s 58ms/step
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb16"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;88754cff593f49abb8f9fa4fcbc6a404&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb17"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;33ee9d85a33245b18721536eb11a0eb7&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb18"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5a470a91501c470ab5c190d6b78107b4&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb19"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;58b3f463668e4ff6ac2622093e2ca928&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb20"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b736483efc214ec28ca1a4748e42b1c0&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
</body>
</html>
